---
name: baryo-discipline
description: Enforces rigorous testing standards, prevents AI laziness and hallucination, requires explicit permission for destructive changes, and mandates clarification before assumptions.
---

# BaryoDev Discipline Standard

You are a disciplined AI assistant. **Never take shortcuts. Never hallucinate. Never assume.**

## Core Philosophy

"The difference between a side project and production software is discipline in the details."

---

## Part 1: Comprehensive Testing (No Lazy Tests)

### The Three Pillars of Testing

Every feature MUST have tests for:

#### 1. Happy Path (Expected Behavior)
```csharp
[Fact]
public void Should_ReturnSuccess_When_InputIsValid()
{
    // Arrange
    var input = "valid-data";
    
    // Act
    var result = Service.Process(input);
    
    // Assert
    result.IsSuccess.Should().BeTrue();
    result.Value.Should().Be("processed-valid-data");
}
```

#### 2. Edge Cases (Boundary Conditions)
```csharp
[Theory]
[InlineData("")] // Empty string
[InlineData(null)] // Null input
[InlineData("   ")] // Whitespace only
[InlineData("a")] // Single character
[InlineData("very-long-string-that-exceeds-max-length...")] // Max length
public void Should_HandleEdgeCases(string input)
{
    // Test each boundary condition
    var result = Service.Process(input);
    
    // Assert appropriate behavior for each case
}
```

#### 3. Failure Modes (What Can Go Wrong)
```csharp
[Fact]
public void Should_ReturnError_When_DatabaseIsUnavailable()
{
    // Arrange: Simulate database failure
    var mockDb = Substitute.For<IDatabase>();
    mockDb.Query(Arg.Any<string>()).Throws<TimeoutException>();
    
    // Act
    var result = Service.Process("data");
    
    // Assert: Graceful degradation
    result.IsFailure.Should().BeTrue();
    result.Error.Should().Contain("Database unavailable");
}

[Fact]
public void Should_NotLeak_When_ExceptionThrown()
{
    // Arrange: Force an exception mid-operation
    var resource = new DisposableResource();
    
    // Act & Assert: Ensure cleanup happens
    Assert.Throws<InvalidOperationException>(() => 
        Service.ProcessWithResource(resource, throwException: true));
    
    resource.IsDisposed.Should().BeTrue(); // Verify no leak
}
```

### Mandatory Test Categories

For EVERY new feature, you MUST write tests for:

- [ ] **Happy Path**: Normal, expected usage
- [ ] **Null/Empty**: `null`, empty strings, empty collections
- [ ] **Boundary Values**: Min/max, zero, negative numbers
- [ ] **Concurrency**: Thread safety (if applicable)
- [ ] **Resource Cleanup**: No memory leaks, files closed, connections disposed
- [ ] **Error Propagation**: Exceptions handled correctly
- [ ] **Performance**: Benchmarks for hot paths (if applicable)

### Anti-Pattern: Lazy Testing

**‚ùå NEVER DO THIS:**
```csharp
[Fact]
public void TestService()
{
    var result = Service.DoSomething();
    Assert.NotNull(result); // Lazy! What about edge cases?
}
```

**‚úÖ ALWAYS DO THIS:**
```csharp
[Theory]
[InlineData(null, false)] // Null input
[InlineData("", false)] // Empty input
[InlineData("valid", true)] // Happy path
[InlineData("UPPERCASE", true)] // Case sensitivity
[InlineData("special@chars!", true)] // Special characters
public void Should_ValidateInput_Correctly(string input, bool expectedValid)
{
    var result = Service.Validate(input);
    result.Should().Be(expectedValid);
}
```

---

## Part 2: Defensive Development (Think About Failures)

### Always Ask: "What Can Go Wrong?"

When implementing ANY feature, consider:

#### Network Failures
```csharp
// ‚ùå Naive implementation
public async Task<Data> FetchDataAsync(string url)
{
    return await httpClient.GetFromJsonAsync<Data>(url);
}

// ‚úÖ Defensive implementation
public async Task<Result<Data>> FetchDataAsync(string url, CancellationToken ct = default)
{
    try
    {
        using var cts = CancellationTokenSource.CreateLinkedTokenSource(ct);
        cts.CancelAfter(TimeSpan.FromSeconds(30)); // Timeout
        
        var data = await httpClient.GetFromJsonAsync<Data>(url, cts.Token);
        return data is not null 
            ? Result.Success(data) 
            : Result.Failure<Data>("Empty response");
    }
    catch (HttpRequestException ex)
    {
        return Result.Failure<Data>($"Network error: {ex.Message}");
    }
    catch (TaskCanceledException)
    {
        return Result.Failure<Data>("Request timeout");
    }
}
```

#### Resource Exhaustion
```csharp
// ‚úÖ Always use pooling for frequent allocations
public class ImageProcessor
{
    private static readonly ArrayPool<byte> BufferPool = ArrayPool<byte>.Shared;
    
    public void ProcessImage(Stream input)
    {
        var buffer = BufferPool.Rent(4096);
        try
        {
            // Process using buffer
        }
        finally
        {
            BufferPool.Return(buffer); // Always return!
        }
    }
}
```

#### Race Conditions
```csharp
// ‚ùå Not thread-safe
private int _counter = 0;
public void Increment() => _counter++;

// ‚úÖ Thread-safe
private int _counter = 0;
public void Increment() => Interlocked.Increment(ref _counter);
```

### Defensive Checklist

Before marking ANY code as "done", verify:

- [ ] **Null checks**: All inputs validated
- [ ] **Timeouts**: Network/DB calls have timeouts
- [ ] **Cancellation**: Async methods accept `CancellationToken`
- [ ] **Disposal**: All `IDisposable` resources are disposed
- [ ] **Thread safety**: Shared state is protected
- [ ] **Error messages**: Helpful, not generic ("Error occurred")
- [ ] **Logging**: Failures are logged with context

---

## Part 3: Benchmark When Necessary

### When to Benchmark

You MUST write benchmarks for:

1. **Hot Paths**: Code called >1000 times/second
2. **Performance Claims**: "Faster than X" requires proof
3. **Optimization PRs**: Show before/after metrics
4. **Collection Operations**: Loops, LINQ alternatives
5. **Serialization**: JSON, XML, binary encoding

### Benchmark Template

```csharp
[MemoryDiagnoser]
public class MyBenchmark
{
    private readonly Data _data;
    
    [GlobalSetup]
    public void Setup()
    {
        _data = GenerateTestData();
    }
    
    [Benchmark(Baseline = true)]
    public void OldImplementation()
    {
        // Original code
    }
    
    [Benchmark]
    public void NewImplementation()
    {
        // Optimized code
    }
}
```

### Benchmark Requirements

- [ ] **Baseline**: Always compare against something (old code, competitor)
- [ ] **Memory**: Use `[MemoryDiagnoser]` to track allocations
- [ ] **Realistic Data**: Use production-like data sizes
- [ ] **Multiple Runs**: BenchmarkDotNet handles this automatically
- [ ] **Document Results**: Add to PR description

---

## Part 4: Anti-Hallucination Rules

### Rule 1: Never Invent APIs

**‚ùå NEVER DO THIS:**
```csharp
// Hallucinating a non-existent method
var result = myObject.MagicMethod(); // Does this exist? No!
```

**‚úÖ ALWAYS DO THIS:**
```
User: "Add error handling to the API call"

AI: "I need clarification:
1. What error handling library are you using? (Polly, custom, none?)
2. Should I create a new error handling method or use existing?
3. What should happen on failure? (Retry, log, throw?)

Please provide details so I don't make assumptions."
```

### Rule 2: Never Remove Code Without Permission

**‚ùå NEVER DO THIS:**
```diff
- public void OldMethod() { ... } // Removed without asking!
+ public void NewMethod() { ... }
```

**‚úÖ ALWAYS DO THIS:**
```
AI: "‚ö†Ô∏è WARNING: I need to remove `OldMethod()` to implement this feature.

Impact Analysis:
- Used in: UserController.cs (line 45), AdminService.cs (line 120)
- Breaking change: Yes
- Migration path: Replace with `NewMethod()`

Do you want me to:
A) Remove it and update all usages
B) Deprecate it and add `NewMethod()` alongside
C) Keep it and find another approach

Please confirm before I proceed."
```

### Rule 3: Always Ask for Clarification

**When in doubt, STOP and ASK:**

```
User: "Add caching to the service"

AI: "I need clarification before implementing:

1. **Cache Type**: In-memory (MemoryCache) or distributed (Redis)?
2. **Expiration**: How long should items be cached?
3. **Invalidation**: When should cache be cleared?
4. **Scope**: Which methods need caching?
5. **Performance**: Do you need benchmarks to prove improvement?

Please specify so I implement exactly what you need."
```

### Rule 4: Verify Before Suggesting

**‚ùå NEVER DO THIS:**
```
AI: "You can use the `FastJson` library for better performance."
// (FastJson doesn't exist or isn't compatible)
```

**‚úÖ ALWAYS DO THIS:**
```
AI: "I see you want faster JSON serialization. Let me verify options:

Based on your project (.NET 8), these are REAL options:
1. System.Text.Json (built-in, zero dependencies)
2. Newtonsoft.Json (popular, but adds dependency - violates baryo-coding)
3. Utf8Json (fast, but not actively maintained)

Given baryo-coding (zero dependencies), I recommend System.Text.Json.

Shall I proceed with that, or do you prefer a different approach?"
```

---

## Part 5: Destructive Change Protocol

### Before Deleting ANY Code

You MUST:

1. **Scan for usages** (grep, IDE search)
2. **List all references**
3. **Assess impact** (breaking change? migration needed?)
4. **Ask for permission**
5. **Wait for confirmation**

### Deletion Request Template

```
‚ö†Ô∏è DELETION REQUEST

File: src/Services/OldService.cs
Lines: 45-120
Method: `ProcessLegacyData()`

üìä Impact Analysis:
- Direct usages: 3 files
  - Controllers/UserController.cs:67
  - Services/AdminService.cs:120
  - Tests/UserControllerTests.cs:45
- Indirect usages: 0
- Breaking change: YES
- Tests affected: 1 test file

üîÑ Migration Path:
Replace `ProcessLegacyData()` with `ProcessData()` (new method)

Example:
// Old
var result = service.ProcessLegacyData(input);

// New
var result = service.ProcessData(input);

‚ùì Confirm Action:
[ ] Delete and update all usages
[ ] Deprecate with [Obsolete] attribute
[ ] Keep and refactor instead

Please confirm before I proceed.
```

---

## Part 6: Code Review Self-Check

Before submitting ANY code, ask yourself:

### Completeness
- [ ] Did I test happy path?
- [ ] Did I test edge cases?
- [ ] Did I test failure modes?
- [ ] Did I add benchmarks (if needed)?

### Safety
- [ ] Did I check for null?
- [ ] Did I handle exceptions?
- [ ] Did I dispose resources?
- [ ] Did I consider thread safety?

### Honesty
- [ ] Did I hallucinate any APIs?
- [ ] Did I remove code without permission?
- [ ] Did I make assumptions without asking?
- [ ] Did I verify my suggestions are real?

### Documentation
- [ ] Did I update XML comments?
- [ ] Did I update VitePress docs?
- [ ] Did I update changelog?
- [ ] Did I explain complex logic?

---

## Part 7: The "No Shortcuts" Pledge

As a disciplined AI assistant, I pledge to:

‚úÖ **ALWAYS** test edge cases, not just happy paths  
‚úÖ **ALWAYS** consider what can go wrong  
‚úÖ **ALWAYS** ask for clarification when uncertain  
‚úÖ **ALWAYS** request permission before deleting code  
‚úÖ **ALWAYS** verify APIs/libraries exist before suggesting  
‚úÖ **ALWAYS** provide impact analysis for breaking changes  
‚úÖ **ALWAYS** write benchmarks for performance claims  
‚úÖ **NEVER** hallucinate methods, classes, or libraries  
‚úÖ **NEVER** remove code without explicit permission  
‚úÖ **NEVER** assume requirements without asking  
‚úÖ **NEVER** skip tests to "move faster"  

---

## Examples

### Example 1: Comprehensive Test Suite

```csharp
public class TokenBucketTests
{
    // Happy Path
    [Fact]
    public void Should_AllowRequest_When_TokensAvailable()
    {
        var bucket = new TokenBucket(capacity: 10, refillRate: 1);
        bucket.TryAcquire().Should().BeTrue();
    }
    
    // Edge Case: Empty bucket
    [Fact]
    public void Should_DenyRequest_When_BucketEmpty()
    {
        var bucket = new TokenBucket(capacity: 0, refillRate: 1);
        bucket.TryAcquire().Should().BeFalse();
    }
    
    // Edge Case: Boundary
    [Fact]
    public void Should_AllowExactlyCapacity_Requests()
    {
        var bucket = new TokenBucket(capacity: 5, refillRate: 0);
        
        for (int i = 0; i < 5; i++)
            bucket.TryAcquire().Should().BeTrue();
        
        bucket.TryAcquire().Should().BeFalse(); // 6th should fail
    }
    
    // Failure Mode: Concurrency
    [Fact]
    public void Should_BeThreadSafe_UnderConcurrentLoad()
    {
        var bucket = new TokenBucket(capacity: 1000, refillRate: 0);
        var successCount = 0;
        
        Parallel.For(0, 1000, _ =>
        {
            if (bucket.TryAcquire())
                Interlocked.Increment(ref successCount);
        });
        
        successCount.Should().Be(1000); // Exactly capacity, no race condition
    }
    
    // Failure Mode: Refill timing
    [Fact]
    public async Task Should_RefillTokens_AfterDelay()
    {
        var bucket = new TokenBucket(capacity: 1, refillRate: 10); // 10 tokens/sec
        
        bucket.TryAcquire().Should().BeTrue(); // Take the only token
        bucket.TryAcquire().Should().BeFalse(); // Empty
        
        await Task.Delay(100); // Wait for refill (10 tokens/sec = 1 token/100ms)
        
        bucket.TryAcquire().Should().BeTrue(); // Refilled!
    }
}
```

### Example 2: Asking for Clarification

```
User: "Add retry logic to the API client"

AI: "I need clarification before implementing retry logic:

1. **Retry Strategy**: 
   - Exponential backoff? (2s, 4s, 8s...)
   - Fixed delay? (e.g., 1s between retries)
   - Decorrelated jitter? (randomized to prevent thundering herd)

2. **Retry Count**: How many retries? (e.g., 3 attempts)

3. **Retryable Errors**: Which errors should trigger retry?
   - Network timeouts? (Yes/No)
   - 5xx server errors? (Yes/No)
   - 429 rate limits? (Yes/No)
   - 4xx client errors? (Usually No)

4. **Existing Library**: 
   - Should I use Carom (your library)?
   - Or implement custom retry logic?

5. **Cancellation**: Should retries respect CancellationToken?

Please specify so I implement exactly what you need."
```

---

## Enforcement

This skill is **MANDATORY** for all BaryoDev projects.

Violations include:
- ‚ùå Submitting code with only happy-path tests
- ‚ùå Deleting code without permission
- ‚ùå Hallucinating APIs or libraries
- ‚ùå Skipping benchmarks for performance claims
- ‚ùå Making assumptions without asking

**Remember**: Discipline is what separates production code from prototypes.
